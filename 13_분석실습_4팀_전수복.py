# -*- coding: utf-8 -*-
"""13_분석실습_4팀_전수복

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nRFODv49FSuQ9-RnxwPOGZdmnO_olLPS

#사전 작업
"""

# Sprint Mission 13: 자전거 대여 수요 예측
# 1️. 기본 세팅 및 데이터 로드
from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from xgboost import XGBRegressor
from xgboost.callback import EarlyStopping

# 나눔고딕 폰트를 설치합니다.
!apt-get install -y fonts-nanum
!fc-cache -fv
# 설치된 나눔고딕 폰트를 matplotlib에 등록합니다.
font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
fm.fontManager.addfont(font_path)
plt.rcParams['font.family'] = 'NanumGothic'
# 폰트가 잘 설정되었는지 테스트합니다.
plt.text(0.5, 0.5, '안녕하세요, 나눔고딕!', ha='center', va='center', size=24)
plt.show()

bank = pd.read_csv('/content/drive/MyDrive/bank-additional-full.csv', sep=';', quotechar='"')

print("bank shape:", bank.shape)
display(bank.head())

bank.head(10)

"""# 데이터 EDA"""

# 기본 정보 확인
bank.info()
bank.describe(include='all').T

# 결측치 확인
print(bank.isnull().sum())
print(bank.nunique())

# 타깃 변수(y) 비율 확인
plt.figure(figsize=(5,4))
sns.countplot(x='y', data=bank)
plt.title("정기예금 가입 여부 분포")
plt.show()

print("비율:\n", bank['y'].value_counts(normalize=True))

# 주요 변수별 탐색
## (1) 연령 분포
sns.histplot(bank['age'], bins=20, kde=True)
plt.title('연령 분포')
plt.show()

## (2) 직업별 분포
plt.figure(figsize=(10,4))
sns.countplot(y='job', data=bank, order=bank['job'].value_counts().index)
plt.title('직업 분포')
plt.show()

## (3) 결혼 상태 vs 마케팅 성공률
plt.figure(figsize=(6,4))
sns.barplot(
    x='marital',
    y=bank['y'].apply(lambda x: 1 if x=='yes' else 0),
    data=bank
)
plt.title('결혼 상태별 성공률')
plt.show()

# 수치형 변수 탐색
num_cols = bank.select_dtypes(include=['int64','float64']).columns
bank[num_cols].hist(figsize=(12,8), bins=20)
plt.suptitle("수치형 변수 분포", fontsize=14)
plt.show()

# 주요 변수별 타깃 비교 (범주형)
cat_cols = ['job','marital','education','housing','loan','contact','month','day_of_week']
for col in cat_cols:
    plt.figure(figsize=(6,3))
    sns.barplot(x=col, y=bank['y'].replace({'yes':1,'no':0}), data=bank, estimator=np.mean)
    plt.xticks(rotation=45)
    plt.title(f"{col}별 정기예금 가입률")
    plt.show()

bank['y_bin'] = bank['y'].map({'yes':1, 'no':0})

for col in ['job', 'marital', 'education', 'contact', 'month', 'poutcome']:
    plt.figure(figsize=(7,4))
    sns.barplot(x=col, y='y_bin', data=bank, estimator='mean')
    plt.title(f'{col}별 예금 가입률')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

corr = bank.corr(numeric_only=True)
plt.figure(figsize=(10,6))
sns.heatmap(corr[['y_bin']].sort_values(by='y_bin', ascending=False), annot=True, cmap='Blues')
plt.title('타겟(y)과의 상관관계')
plt.show()

# 파생 변수 생성
bank['is_weekend'] = bank['day_of_week'].apply(lambda x: 1 if x=='fri' else 0)
bank['call_efficiency'] = bank['duration'] / (bank['campaign'] + 1)
bank['age_group'] = pd.cut(bank['age'], bins=[17,29,39,49,59,69,99], labels=['20s','30s','40s','50s','60s','70+'])

# econ_index 계산 시 수치형 변수만 선택
num_cols_for_econ = ['emp.var.rate','cons.price.idx','cons.conf.idx','euribor3m','nr.employed']
bank['econ_index'] = bank[num_cols_for_econ].mean(axis=1)

bank.head(3)

bank['age_group'] = bank['age_group'].astype(str)

# duration 변수 처리 (예측 시 제외)
X = bank.drop(['y','duration'], axis=1)
y = bank['y'].map({'yes':1, 'no':0})

# 범주형 변수 인코딩
cat_features = X.select_dtypes('object').columns
X = pd.get_dummies(X, columns=cat_features, drop_first=True)

"""# 모델 만들기"""

# 데이터 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
print("훈련 데이터 크기:", X_train.shape)
print("테스트 데이터 크기:", X_test.shape)

# 베이스라인 모델 (로지스틱 회귀)
log_model = LogisticRegression(max_iter=1000)
log_model.fit(X_train, y_train)

y_pred_log = log_model.predict(X_test)
y_pred_prob_log = log_model.predict_proba(X_test)[:,1]

print("Logistic Regression 성능")
print("Accuracy:", accuracy_score(y_test, y_pred_log))
print("Precision:", precision_score(y_test, y_pred_log))
print("Recall:", recall_score(y_test, y_pred_log))
print("F1:", f1_score(y_test, y_pred_log))
print("AUC:", roc_auc_score(y_test, y_pred_prob_log))

# 앙상블 모델 (Random Forest, XGBoost)
rf = RandomForestClassifier(n_estimators=200, random_state=42)
xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)

rf.fit(X_train, y_train)
xgb.fit(X_train, y_train)

models = {'Random Forest': rf, 'XGBoost': xgb}

for name, model in models.items():
    y_pred = model.predict(X_test)
    y_prob = model.predict_proba(X_test)[:,1]
    print(f"{name} 성능")
    print("Accuracy:", accuracy_score(y_test, y_pred))
    print("Precision:", precision_score(y_test, y_pred))
    print("Recall:", recall_score(y_test, y_pred))
    print("F1:", f1_score(y_test, y_pred))
    print("AUC:", roc_auc_score(y_test, y_prob))

# ROC 커브 시각화
plt.figure(figsize=(6,5))
for name, model in models.items():
    y_prob = model.predict_proba(X_test)[:,1]
    fpr, tpr, _ = roc_curve(y_test, y_prob)
    plt.plot(fpr, tpr, label=f"{name} (AUC={roc_auc_score(y_test,y_prob):.3f})")

plt.plot([0,1],[0,1],'--',color='gray')
plt.legend()
plt.title("ROC Curve 비교")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.show()

# 변수 중요도 (XGBoost)
importance = pd.Series(xgb.feature_importances_, index=X.columns).sort_values(ascending=False)[:10]
plt.figure(figsize=(7,4))
sns.barplot(x=importance.values, y=importance.index)
plt.title("XGBoost 상위 중요 변수")
plt.show()

# SMOTE (Over-sampling, 소수 클래스 증강)
from imblearn.over_sampling import SMOTE

sm = SMOTE(random_state=42)
X_res, y_res = sm.fit_resample(X_train, y_train)

print("Before SMOTE:", y_train.value_counts(normalize=True))
print("After SMOTE:", y_res.value_counts(normalize=True))

# XGBoost 학습
xgb_sm = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
xgb_sm.fit(X_res, y_res)

y_pred_sm = xgb_sm.predict(X_test)
y_prob_sm = xgb_sm.predict_proba(X_test)[:,1]

print("SMOTE 적용 후 XGBoost 성능")
print("Accuracy:", accuracy_score(y_test, y_pred_sm))
print("Precision:", precision_score(y_test, y_pred_sm))
print("Recall:", recall_score(y_test, y_pred_sm))
print("F1:", f1_score(y_test, y_pred_sm))
print("AUC:", roc_auc_score(y_test, y_prob_sm))

